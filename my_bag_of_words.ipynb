{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/W4wRatIvG94vQeESak8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandossrecife/mysentimentanalysis/blob/main/my_bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo 1"
      ],
      "metadata": {
        "id": "jH7sm4lSKZn9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRImJPsKKBCW",
        "outputId": "105bb5d2-d29a-40c8-af09-95c395a3fc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['brown' 'dog' 'fox' 'is' 'it' 'jumps' 'lazy' 'over' 'quick' 'slowly'\n",
            " 'the']\n",
            "[[1 1 1 0 0 1 1 1 1 0 2]\n",
            " [1 1 1 1 1 1 1 1 0 1 2]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"The dog is lazy. It jumps slowly over the brown fox.\"\n",
        "]\n",
        "# Preprocessing (optional)\n",
        "# You can add additional preprocessing steps like stop word removal here\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the documents (learn the vocabulary)\n",
        "vectorizer.fit(documents)\n",
        "\n",
        "# Transform the documents into BoW feature vectors\n",
        "bow_matrix = vectorizer.transform(documents)\n",
        "\n",
        "# Print the vocabulary (unique words)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "# Print the BoW feature vectors as a dense matrix (easier to read)\n",
        "print(bow_matrix.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo 2"
      ],
      "metadata": {
        "id": "J-jLSxKAKcXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to install the necessary packages first\n",
        "# pip install --upgrade pip\n",
        "# pip install tensorflow\n",
        "from tensorflow import keras\n",
        "from typing import List\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "p1 = \"Sarah enjoys watching fantasy movies in her free time. Michael likes watching them too, especially ones with dragons\"\n",
        "p2 = \"Lisa loves baking delicious cookies and watching movies on weekends. Her brother David enjoys watching movies with her while they enjoy the cookies\"\n",
        "p3 = \"The park is a great place to relax and watch movies outdoors on a projector. Many people come here to unwind after work and enjoy a movie under the stars\"\n",
        "p4 = \"Learning a new language can be challenging, but watching movies with subtitles in that language can be a fun way to practice. The rewards of fluency are definitely worth it. 5. Traveling to new places broadens your horizons and exposes you to new cultures. Watching movies made in those countries can be a great way to experience their stories and traditions\"\n",
        "\n",
        "sentence1 = [p1]\n",
        "sentence2 = [p2]\n",
        "sentence3 = [p3]\n",
        "sentence4 = [p4]\n",
        "\n",
        "def print_bow(sentence: List[str]) -> None:\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentence)\n",
        "    sequences = tokenizer.texts_to_sequences(sentence)\n",
        "    word_index = tokenizer.word_index\n",
        "    bow = {}\n",
        "    for key in word_index:\n",
        "        bow[key] = sequences[0].count(word_index[key])\n",
        "\n",
        "    print(f\"Bag of word sentence :\\n{bow}\")\n",
        "    print(f\"We found {len(word_index)} unique tokens.\")"
      ],
      "metadata": {
        "id": "b7_b3Q3UKdGm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_bow(sentence1)\n",
        "print_bow(sentence2)\n",
        "print_bow(sentence3)\n",
        "print_bow(sentence4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki0IKolaL3si",
        "outputId": "1f111c47-db89-47ba-c264-fd73865278e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of word sentence 1:\n",
            "{'watching': 2, 'sarah': 1, 'enjoys': 1, 'fantasy': 1, 'movies': 1, 'in': 1, 'her': 1, 'free': 1, 'time': 1, 'michael': 1, 'likes': 1, 'them': 1, 'too': 1, 'especially': 1, 'ones': 1, 'with': 1, 'dragons': 1}\n",
            "We found 17 unique tokens.\n",
            "Bag of word sentence 1:\n",
            "{'cookies': 2, 'watching': 2, 'movies': 2, 'her': 2, 'lisa': 1, 'loves': 1, 'baking': 1, 'delicious': 1, 'and': 1, 'on': 1, 'weekends': 1, 'brother': 1, 'david': 1, 'enjoys': 1, 'with': 1, 'while': 1, 'they': 1, 'enjoy': 1, 'the': 1}\n",
            "We found 19 unique tokens.\n",
            "Bag of word sentence 1:\n",
            "{'a': 3, 'the': 2, 'to': 2, 'and': 2, 'park': 1, 'is': 1, 'great': 1, 'place': 1, 'relax': 1, 'watch': 1, 'movies': 1, 'outdoors': 1, 'on': 1, 'projector': 1, 'many': 1, 'people': 1, 'come': 1, 'here': 1, 'unwind': 1, 'after': 1, 'work': 1, 'enjoy': 1, 'movie': 1, 'under': 1, 'stars': 1}\n",
            "We found 25 unique tokens.\n",
            "Bag of word sentence 1:\n",
            "{'to': 4, 'a': 3, 'new': 3, 'can': 3, 'be': 3, 'language': 2, 'watching': 2, 'movies': 2, 'in': 2, 'way': 2, 'and': 2, 'learning': 1, 'challenging': 1, 'but': 1, 'with': 1, 'subtitles': 1, 'that': 1, 'fun': 1, 'practice': 1, 'the': 1, 'rewards': 1, 'of': 1, 'fluency': 1, 'are': 1, 'definitely': 1, 'worth': 1, 'it': 1, '5': 1, 'traveling': 1, 'places': 1, 'broadens': 1, 'your': 1, 'horizons': 1, 'exposes': 1, 'you': 1, 'cultures': 1, 'made': 1, 'those': 1, 'countries': 1, 'great': 1, 'experience': 1, 'their': 1, 'stories': 1, 'traditions': 1}\n",
            "We found 44 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_p = p1 + p2 + p3 + p4\n",
        "all_sentences = [all_p]\n",
        "print_bow(all_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6uF2U5iNdnm",
        "outputId": "afa6a54e-00a2-4e8a-acdf-a50d153b0bcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of word sentence :\n",
            "{'watching': 6, 'movies': 6, 'a': 6, 'to': 6, 'and': 5, 'in': 3, 'her': 3, 'with': 3, 'the': 3, 'new': 3, 'can': 3, 'be': 3, 'enjoys': 2, 'on': 2, 'enjoy': 2, 'great': 2, 'language': 2, 'way': 2, 'sarah': 1, 'fantasy': 1, 'free': 1, 'time': 1, 'michael': 1, 'likes': 1, 'them': 1, 'too': 1, 'especially': 1, 'ones': 1, 'dragonslisa': 1, 'loves': 1, 'baking': 1, 'delicious': 1, 'cookies': 1, 'weekends': 1, 'brother': 1, 'david': 1, 'while': 1, 'they': 1, 'cookiesthe': 1, 'park': 1, 'is': 1, 'place': 1, 'relax': 1, 'watch': 1, 'outdoors': 1, 'projector': 1, 'many': 1, 'people': 1, 'come': 1, 'here': 1, 'unwind': 1, 'after': 1, 'work': 1, 'movie': 1, 'under': 1, 'starslearning': 1, 'challenging': 1, 'but': 1, 'subtitles': 1, 'that': 1, 'fun': 1, 'practice': 1, 'rewards': 1, 'of': 1, 'fluency': 1, 'are': 1, 'definitely': 1, 'worth': 1, 'it': 1, '5': 1, 'traveling': 1, 'places': 1, 'broadens': 1, 'your': 1, 'horizons': 1, 'exposes': 1, 'you': 1, 'cultures': 1, 'made': 1, 'those': 1, 'countries': 1, 'experience': 1, 'their': 1, 'stories': 1, 'traditions': 1}\n",
            "We found 85 unique tokens.\n"
          ]
        }
      ]
    }
  ]
}