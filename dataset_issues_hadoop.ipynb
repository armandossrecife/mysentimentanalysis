{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandossrecife/mysentimentanalysis/blob/main/dataset_issues_hadoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC-IRn3Wy9B8"
      },
      "outputs": [],
      "source": [
        "!rm -rf *.xlsx\n",
        "!rm -rf *.zip\n",
        "!rm -rf my_issues"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Technical-Debt-Large-Scale/my_validation/main/hadoop/hadoop_issues_inspected.xlsx\n",
        "!wget https://raw.githubusercontent.com/Technical-Debt-Large-Scale/my_validation/main/hadoop/my_issues_to_inspection_hadoop.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tuuosdFy-yk",
        "outputId": "9c11268c-02a7-4c52-f06d-ac153851bb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-01 21:21:57--  https://raw.githubusercontent.com/Technical-Debt-Large-Scale/my_validation/main/hadoop/hadoop_issues_inspected.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23670 (23K) [application/octet-stream]\n",
            "Saving to: ‘hadoop_issues_inspected.xlsx’\n",
            "\n",
            "hadoop_issues_inspe 100%[===================>]  23.12K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-08-01 21:21:58 (3.87 MB/s) - ‘hadoop_issues_inspected.xlsx’ saved [23670/23670]\n",
            "\n",
            "--2024-08-01 21:21:58--  https://raw.githubusercontent.com/Technical-Debt-Large-Scale/my_validation/main/hadoop/my_issues_to_inspection_hadoop.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225975 (221K) [application/zip]\n",
            "Saving to: ‘my_issues_to_inspection_hadoop.zip’\n",
            "\n",
            "my_issues_to_inspec 100%[===================>] 220.68K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-08-01 21:21:59 (1.84 MB/s) - ‘my_issues_to_inspection_hadoop.zip’ saved [225975/225975]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip my_issues_to_inspection_hadoop.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV9M5VSYzBbe",
        "outputId": "a799fca6-6d15-4793-df1e-3a3a74dd3eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  my_issues_to_inspection_hadoop.zip\n",
            "   creating: my_issues/\n",
            "  inflating: my_issues/HADOOP-10402  \n",
            "  inflating: my_issues/HADOOP-6471   \n",
            "  inflating: my_issues/HADOOP-6252   \n",
            "  inflating: my_issues/HADOOP-10682  \n",
            "  inflating: my_issues/HADOOP-6323   \n",
            "  inflating: my_issues/HADOOP-7524   \n",
            "  inflating: my_issues/HADOOP-9582   \n",
            "  inflating: my_issues/HADOOP-16596  \n",
            "  inflating: my_issues/HADOOP-9688   \n",
            "  inflating: my_issues/HADOOP-13706  \n",
            "  inflating: my_issues/HADOOP-17088  \n",
            "  inflating: my_issues/HADOOP-6165   \n",
            "  inflating: my_issues/HADOOP-6269   \n",
            "  inflating: my_issues/HADOOP-10482  \n",
            "  inflating: my_issues/HADOOP-8359   \n",
            "  inflating: my_issues/HADOOP-12916  \n",
            "  inflating: my_issues/HADOOP-18229  \n",
            "  inflating: my_issues/HADOOP-10208  \n",
            "  inflating: my_issues/HADOOP-6184   \n",
            "  inflating: my_issues/HADOOP-6312   \n",
            "  inflating: my_issues/HADOOP-8573   \n",
            "  inflating: my_issues/HADOOP-7287   \n",
            "  inflating: my_issues/HADOOP-16951  \n",
            "  inflating: my_issues/HADOOP-8362   \n",
            "  inflating: my_issues/HADOOP-11852  \n",
            "  inflating: my_issues/HADOOP-18190  \n",
            "  inflating: my_issues/HADOOP-16654  \n",
            "  inflating: my_issues/HADOOP-10625  \n",
            "  inflating: my_issues/HADOOP-15554  \n",
            "  inflating: my_issues/HADOOP-7910   \n",
            "  inflating: my_issues/HADOOP-6313   \n",
            "  inflating: my_issues/HADOOP-6443   \n",
            "  inflating: my_issues/HADOOP-17358  \n",
            "  inflating: my_issues/HADOOP-16906  \n",
            "  inflating: my_issues/HADOOP-17424  \n",
            "  inflating: my_issues/HADOOP-10607  \n",
            "  inflating: my_issues/HADOOP-6964   \n",
            "  inflating: my_issues/HADOOP-8821   \n",
            "  inflating: my_issues/HADOOP-8952   \n",
            "  inflating: my_issues/HADOOP-6671   \n",
            "  inflating: my_issues/HADOOP-7145   \n",
            "  inflating: my_issues/HADOOP-8349   \n",
            "  inflating: my_issues/HADOOP-17123  \n",
            "  inflating: my_issues/HADOOP-18266  \n",
            "  inflating: my_issues/HADOOP-11741  \n",
            "  inflating: my_issues/HADOOP-18318  \n",
            "  inflating: my_issues/HADOOP-11399  \n",
            "  inflating: my_issues/HADOOP-7106   \n",
            "  inflating: my_issues/HADOOP-8286   \n",
            "  inflating: my_issues/HADOOP-17613  \n",
            "  inflating: my_issues/HADOOP-9686   \n",
            "  inflating: my_issues/HADOOP-6623   \n",
            "  inflating: my_issues/HADOOP-8240   \n",
            "  inflating: my_issues/HADOOP-14260  \n",
            "  inflating: my_issues/HADOOP-10248  \n",
            "  inflating: my_issues/HADOOP-15331  \n",
            "  inflating: my_issues/HADOOP-6791   \n",
            "  inflating: my_issues/HADOOP-11209  \n",
            "  inflating: my_issues/HADOOP-9649   \n",
            "  inflating: my_issues/HADOOP-7001   \n",
            "  inflating: my_issues/HADOOP-13628  \n",
            "  inflating: my_issues/HADOOP-14503  \n",
            "  inflating: my_issues/HADOOP-6346   \n",
            "  inflating: my_issues/HADOOP-8227   \n",
            "  inflating: my_issues/HADOOP-14938  \n",
            "  inflating: my_issues/HADOOP-14038  \n",
            "  inflating: my_issues/HADOOP-7451   \n",
            "  inflating: my_issues/HADOOP-7082   \n",
            "  inflating: my_issues/HADOOP-9323   \n",
            "  inflating: my_issues/HADOOP-13442  \n",
            "  inflating: my_issues/HADOOP-14251  \n",
            "  inflating: my_issues/HADOOP-14701  \n",
            "  inflating: my_issues/HADOOP-15755  \n",
            "  inflating: my_issues/HADOOP-16084  \n",
            "  inflating: my_issues/HADOOP-11274  \n",
            "  inflating: my_issues/HADOOP-10075  \n",
            "  inflating: my_issues/HADOOP-13327  \n",
            "  inflating: my_issues/HADOOP-16265  \n",
            "  inflating: my_issues/HADOOP-13441  \n",
            "  inflating: my_issues/HADOOP-14727  \n",
            "  inflating: my_issues/HADOOP-9318   \n",
            "  inflating: my_issues/HADOOP-17957  \n",
            "  inflating: my_issues/HADOOP-18379  \n",
            "  inflating: my_issues/HADOOP-8335   \n",
            "  inflating: my_issues/HADOOP-7664   \n",
            "  inflating: my_issues/HADOOP-13770  \n",
            "  inflating: my_issues/HADOOP-6502   \n",
            "  inflating: my_issues/HADOOP-8325   \n",
            "  inflating: my_issues/HADOOP-12321  \n",
            "  inflating: my_issues/HADOOP-17288  \n",
            "  inflating: my_issues/HADOOP-18014  \n",
            "  inflating: my_issues/HADOOP-9618   \n",
            "  inflating: my_issues/HADOOP-16282  \n",
            "  inflating: my_issues/HADOOP-6578   \n",
            "  inflating: my_issues/HADOOP-9604   \n",
            "  inflating: my_issues/HADOOP-8525   \n",
            "  inflating: my_issues/HADOOP-12862  \n",
            "  inflating: my_issues/HADOOP-10873  \n",
            "  inflating: my_issues/HADOOP-9252   \n",
            "  inflating: my_issues/HADOOP-7046   \n",
            "  inflating: my_issues/HADOOP-6161   \n",
            "  inflating: my_issues/HADOOP-14341  \n",
            "  inflating: my_issues/HADOOP-7118   \n",
            "  inflating: my_issues/HADOOP-8172   \n",
            "  inflating: my_issues/HADOOP-8608   \n",
            "  inflating: my_issues/HADOOP-9784   \n",
            "  inflating: my_issues/HADOOP-7851   \n",
            "  inflating: my_issues/HADOOP-15357  \n",
            "  inflating: my_issues/HADOOP-11389  \n",
            "  inflating: my_issues/HADOOP-18028  \n",
            "  inflating: my_issues/HADOOP-12317  \n",
            "  inflating: my_issues/HADOOP-10345  \n",
            "  inflating: my_issues/HADOOP-11416  \n",
            "  inflating: my_issues/HADOOP-6698   \n",
            "  inflating: my_issues/HADOOP-8780   \n",
            "  inflating: my_issues/HADOOP-17959  \n",
            "  inflating: my_issues/HADOOP-9361   \n",
            "  inflating: my_issues/HADOOP-6802   \n",
            "  inflating: my_issues/HADOOP-15708  \n",
            "  inflating: my_issues/HADOOP-16830  \n",
            "  inflating: my_issues/HADOOP-12639  \n",
            "  inflating: my_issues/HADOOP-7993   \n",
            "  inflating: my_issues/HADOOP-6103   \n",
            "  inflating: my_issues/HADOOP-18180  \n",
            "  inflating: my_issues/HADOOP-7151   \n",
            "  inflating: my_issues/HADOOP-6420   \n",
            "  inflating: my_issues/HADOOP-12457  \n",
            "  inflating: my_issues/HADOOP-11506  \n",
            "  inflating: my_issues/HADOOP-16218  \n",
            "  inflating: my_issues/HADOOP-17963  \n",
            "  inflating: my_issues/HADOOP-8167   \n",
            "  inflating: my_issues/HADOOP-14104  \n",
            "  inflating: my_issues/HADOOP-6298   \n",
            "  inflating: my_issues/HADOOP-9756   \n",
            "  inflating: my_issues/HADOOP-8632   \n",
            "  inflating: my_issues/HADOOP-8124   \n",
            "  inflating: my_issues/HADOOP-12097  \n",
            "  inflating: my_issues/HADOOP-13500  \n",
            "  inflating: my_issues/HADOOP-6521   \n",
            "  inflating: my_issues/HADOOP-10178  \n",
            "  inflating: my_issues/HADOOP-11627  \n",
            "  inflating: my_issues/HADOOP-8157   \n",
            "  inflating: my_issues/HADOOP-11901  \n",
            "  inflating: my_issues/HADOOP-12437  \n",
            "  inflating: my_issues/HADOOP-8524   \n",
            "  inflating: my_issues/HADOOP-8297   \n",
            "  inflating: my_issues/HADOOP-7547   \n",
            "  inflating: my_issues/HADOOP-17079  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "zqXPsHfizFhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_file_issues_to_list_issues(my_files):\n",
        "  list_issues = []\n",
        "  dict_issue = {}\n",
        "  for filename in my_files:\n",
        "    with open(f'my_issues/{filename}', 'r') as f:\n",
        "      content_file = f.read()\n",
        "\n",
        "    issue_key = filename\n",
        "    issue_type = content_file.split('issue_type:')[1].split('\\n')[0]\n",
        "    issue_type = issue_type.replace(' ', '')\n",
        "    summary = content_file.split('summary:')[1].split('\\n')[0]\n",
        "    description = content_file.split('description:')[1].split('status:')[0]\n",
        "    status = content_file.split('status:')[1].split('\\n')[0]\n",
        "    comments = content_file.split('status:')[1].split('comments:')[1]\n",
        "\n",
        "    dict_issue = {\n",
        "          'issue_key': issue_key,\n",
        "          'issue_type': issue_type,\n",
        "          'summary': summary,\n",
        "          'description': description,\n",
        "          'status': status,\n",
        "          'comments': comments\n",
        "    }\n",
        "    list_issues.append(dict_issue)\n",
        "  return list_issues"
      ],
      "metadata": {
        "id": "Y2wxHtcIzKrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_files = os.listdir('my_issues')\n",
        "list_issues = convert_file_issues_to_list_issues(my_files=my_files)\n",
        "df_my_hadoop_selected_issues = pd.DataFrame(list_issues)"
      ],
      "metadata": {
        "id": "4OQSZtuBzMkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_my_hadoop_selected_issues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "RpHNRKBxzTJM",
        "outputId": "0798bd21-682e-424c-cbff-9dabe3f769a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        issue_key   issue_type  \\\n",
              "0    HADOOP-11416  Improvement   \n",
              "1    HADOOP-11399  Improvement   \n",
              "2    HADOOP-17424     Sub-task   \n",
              "3    HADOOP-12321   NewFeature   \n",
              "4    HADOOP-18318     Sub-task   \n",
              "..            ...          ...   \n",
              "143   HADOOP-7451  Improvement   \n",
              "144  HADOOP-10607   NewFeature   \n",
              "145  HADOOP-16218     Sub-task   \n",
              "146   HADOOP-7046          Bug   \n",
              "147   HADOOP-7993          Bug   \n",
              "\n",
              "                                               summary  \\\n",
              "0            Move ChunkedArrayList into hadoop-common    \n",
              "1     Java Configuration file and .xml files should...   \n",
              "2                    Replace HTrace with No-Op tracer    \n",
              "3             Make JvmPauseMonitor an AbstractService    \n",
              "4     Update class names to be clear they belong to...   \n",
              "..                                                 ...   \n",
              "143     merge for MR-279: Generalize StringUtils#join    \n",
              "144   Create an API to Separate Credentials/Passwor...   \n",
              "145   findbugs warning of null param to non-nullabl...   \n",
              "146       1 Findbugs warning on trunk and branch-0.22    \n",
              "147   Hadoop ignores old-style config options for e...   \n",
              "\n",
              "                                           description      status  \\\n",
              "0     Move ChunkedArrayList into hadoop-common so t...     Closed    \n",
              "1     Update common in order to allow automatic com...     Closed    \n",
              "2     Remove HTrace dependency as it is depending o...   Resolved    \n",
              "3     The new JVM pause monitor has been written wi...   Resolved    \n",
              "4     tune classnames, e.g S3InputStream -> S3ABuff...   Resolved    \n",
              "..                                                 ...         ...   \n",
              "143   Fix incomplete merge from yahoo-merge branch ...     Closed    \n",
              "144   As with the filesystem API, we need to provid...     Closed    \n",
              "145   Findbugs is fussing over some unchanged code ...   Resolved    \n",
              "146   There is 1 findbugs warnings on trunk. See at...     Closed    \n",
              "147   Hadoop seems to ignore the config options eve...     Closed    \n",
              "\n",
              "                                              comments  \n",
              "0     No code changes, purely a rename of the file ...  \n",
              "1     Add unit test with no failure modes, but acti...  \n",
              "2     [~smeng] Should we close HADOOP-17387 as dupl...  \n",
              "3     I think this change definitely helps in resol...  \n",
              "4             fixed in the big HADOOP-18181 patch\\n \\n  \n",
              "..                                                 ...  \n",
              "143   Already subject to review during merge of yah...  \n",
              "144   The same general pattern for provider SPIs ha...  \n",
              "145   Thanks for filing this [~stevel@apache.org]!\\...  \n",
              "146   Attached the correct FindBugs report file for...  \n",
              "147   Kindly review.\\n-1 overall.  Here are the res...  \n",
              "\n",
              "[148 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a07faad2-a85e-46b6-b257-13d2e8272c64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_key</th>\n",
              "      <th>issue_type</th>\n",
              "      <th>summary</th>\n",
              "      <th>description</th>\n",
              "      <th>status</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HADOOP-11416</td>\n",
              "      <td>Improvement</td>\n",
              "      <td>Move ChunkedArrayList into hadoop-common</td>\n",
              "      <td>Move ChunkedArrayList into hadoop-common so t...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>No code changes, purely a rename of the file ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HADOOP-11399</td>\n",
              "      <td>Improvement</td>\n",
              "      <td>Java Configuration file and .xml files should...</td>\n",
              "      <td>Update common in order to allow automatic com...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>Add unit test with no failure modes, but acti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HADOOP-17424</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Replace HTrace with No-Op tracer</td>\n",
              "      <td>Remove HTrace dependency as it is depending o...</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>[~smeng] Should we close HADOOP-17387 as dupl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HADOOP-12321</td>\n",
              "      <td>NewFeature</td>\n",
              "      <td>Make JvmPauseMonitor an AbstractService</td>\n",
              "      <td>The new JVM pause monitor has been written wi...</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>I think this change definitely helps in resol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HADOOP-18318</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Update class names to be clear they belong to...</td>\n",
              "      <td>tune classnames, e.g S3InputStream -&gt; S3ABuff...</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>fixed in the big HADOOP-18181 patch\\n \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>HADOOP-7451</td>\n",
              "      <td>Improvement</td>\n",
              "      <td>merge for MR-279: Generalize StringUtils#join</td>\n",
              "      <td>Fix incomplete merge from yahoo-merge branch ...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>Already subject to review during merge of yah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>HADOOP-10607</td>\n",
              "      <td>NewFeature</td>\n",
              "      <td>Create an API to Separate Credentials/Passwor...</td>\n",
              "      <td>As with the filesystem API, we need to provid...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>The same general pattern for provider SPIs ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>HADOOP-16218</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>findbugs warning of null param to non-nullabl...</td>\n",
              "      <td>Findbugs is fussing over some unchanged code ...</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>Thanks for filing this [~stevel@apache.org]!\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>HADOOP-7046</td>\n",
              "      <td>Bug</td>\n",
              "      <td>1 Findbugs warning on trunk and branch-0.22</td>\n",
              "      <td>There is 1 findbugs warnings on trunk. See at...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>Attached the correct FindBugs report file for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>HADOOP-7993</td>\n",
              "      <td>Bug</td>\n",
              "      <td>Hadoop ignores old-style config options for e...</td>\n",
              "      <td>Hadoop seems to ignore the config options eve...</td>\n",
              "      <td>Closed</td>\n",
              "      <td>Kindly review.\\n-1 overall.  Here are the res...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07faad2-a85e-46b6-b257-13d2e8272c64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a07faad2-a85e-46b6-b257-13d2e8272c64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a07faad2-a85e-46b6-b257-13d2e8272c64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8839341-c927-47b5-a8ed-deb6db0daac2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8839341-c927-47b5-a8ed-deb6db0daac2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8839341-c927-47b5-a8ed-deb6db0daac2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_21c0814c-9e05-487f-b16a-b07f9c256431\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_my_hadoop_selected_issues')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_21c0814c-9e05-487f-b16a-b07f9c256431 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_my_hadoop_selected_issues');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_my_hadoop_selected_issues",
              "summary": "{\n  \"name\": \"df_my_hadoop_selected_issues\",\n  \"rows\": 148,\n  \"fields\": [\n    {\n      \"column\": \"issue_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"HADOOP-15708\",\n          \"HADOOP-6103\",\n          \"HADOOP-11901\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Improvement\",\n          \"Sub-task\",\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \" Reading values from Configuration before adding deprecations make it impossible to read value with deprecated key \",\n          \" Configuration clone constructor does not clone all the members. \",\n          \" BytesWritable fails to support 2G chunks due to integer overflow \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 141,\n        \"samples\": [\n          \" If someone calls Configuration.addResource(InputStream) and then reloadConfiguration is called for any reason, Configruation will try to reread the contents of the InputStream, after it has already closed it.\\n\\nThis never showed up in 1.0 because the framework itself does not call addResource with an InputStream, and typically by the time user code starts running that might call this, all of the default and site resources have already been loaded.\\n\\nIn 0.23 mapreduce is now a client library, and mapred-site.xml and mapred-default.xml are loaded much later in the process. \\n\",\n          \" We should allow users to use the more compact form of xml elements. For example, we could allow:\\n{noformat}\\n<property name=\\\"mapred.local.dir\\\" value=\\\"/disk/0/mapred,/disk/1/mapred\\\"/>\\n{noformat}\\nThe old format would also be supported. \\n\",\n          \" According to current implementation of kms provider in client conf, there can only be one kms.\\nIn multi-cluster environment, if a client is reading encrypted data from multiple clusters it will only get kms token for local cluster.\\nNot sure whether the target version is correct or not. \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \" Closed \",\n          \" Resolved \",\n          \" Open \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \" Also humanReadableInt(..) uses oneDecimal without synchronization.  I think it is a bug.\\nc9252_20130127.patch: use String.format(..) and TraditionalBinaryPrefix.\\n{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \\n  http://issues.apache.org/jira/secure/attachment/12566699/c9252_20130127.patch\\n  against trunk revision .\\n\\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\\n\\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\\n\\n      {color:red}-1 javac{color}.  The applied patch generated 2054 javac compiler warnings (more than the trunk's current 2014 warnings).\\n\\n    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 1 warning messages.\\n\\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\\n\\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\\n\\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\\n\\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\\n\\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\\n\\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//testReport/\\nJavac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//artifact/trunk/patchprocess/diffJavacWarnings.txt\\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//console\\n\\nThis message is automatically generated.\\nAll new javac warnings are deprecated warnings.\\n\\nc9252_20130128.patch: fixes the javadoc warning.\\n{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \\n  http://issues.apache.org/jira/secure/attachment/12566806/c9252_20130128.patch\\n  against trunk revision .\\n\\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\\n\\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\\n\\n      {color:red}-1 javac{color}.  The applied patch generated 2054 javac compiler warnings (more than the trunk's current 2014 warnings).\\n\\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\\n\\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\\n\\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\\n\\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\\n\\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\\n\\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\\n\\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//testReport/\\nJavac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//artifact/trunk/patchprocess/diffJavacWarnings.txt\\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//console\\n\\nThis message is automatically generated.\\nHi Nicholas,\\n\\nI'm assuming that for backwards-compatibility, {{StringUtils#limitDecimalTo2}} still needs to keep returning the same output after this patch.  (If that's not the case, please let me know.)\\n\\n{code}\\n-  public static synchronized String limitDecimalTo2(double d) {\\n-    return decimalFormat.format(d);\\n+  /**\\n+   * @deprecated use {@link String#format(String, Object...)},\\n+   *             i.e. String.format(\\\"%.2f\\\", d).\\n+   */\\n+  @Deprecated\\n+  public static String limitDecimalTo2(double d) {\\n+    return String.format(\\\"%.2f\\\", d);\\n   }\\n{code}\\n\\nThe former DecimalFormat \\\"#.##\\\" is not quite equivalent to the new printf format \\\"%.2f\\\".  The former will truncate the output to an integer if there are only non-significant digits (zeroes) remaining on the right side of the decimal point after rounding.  Th \\n\",\n          \" Before we do anything we probably want to set up a micro-benchmark to validate any changes that happen.  I personally don't have much of a problem leaking classes in Hadoop itself so long as we document that it might happen.  We typically don't use one class and then drop it.  In almost all cases we will load a class that is used throughout the life of a process.  I am not sure about other projects that also use Configuration.\\nHi Costin. We added the {{CACHE_CLASSES}} member in HADOOP-6133 to solve a performance regression which we saw in practice. HADOOP-6502 also talks about another case where the performance of this code was critical. So I don't think removing the cache is a good idea. \\n\\nThat said, I do think changing the cache to have weak values as well as weak keys makes sense. Guava's MapMaker has a nice utility to do this, or we could simply change the class values to be Map<String, WeakReference<Class<?>>>.\\n@Robert\\n\\nMy issue is not with the cache itself but with the leakage. If a client submits several big jobs, she has to either launch a new JVM for each submission or somehow patch the leak from outside. Or face OOM.\\nAddressing this in the framework directly obviously is much better.\\n\\n@Todd\\nWrapping the value with a WeakReference probably it's the easiest solution since it doesn't introduce a new library dependency. It can later be upgraded to MapMaker if the pattern occurs often.\\nCostin,\\n\\nI understand your issue more fully now, and I am fine if you want to add in WeakReferences to the ClassLoaders.  If you have a patch for this leak, I would be happy to review it.\\nI've attached my patch. I picked it up from my fork on GitHub (of Hadoop Commons) - based it on hadoop-2.0.1 branch.\\nSee the code here: https://github.com/costin/hadoop-common/commit/57d9df37e600dd588a737d67b271657561ebfea2\\ngit patch\\nBy the way, in the same vein, ReflectionUtils#CONSTRUCTOR_CACHE also leaks classes (see HADOOP-8605 - I'm happy to fix that as well if you want).\\nKicking Jenkins so it will test the patch.\\n-1 overall.  Here are the results of testing the latest attachment \\n  http://issues.apache.org/jira/secure/attachment/12540677/0001-wrapping-classes-with-WeakRefs-in-CLASS_CACHE.patch\\n  against trunk revision .\\n\\n    -1 patch.  The patch command could not apply the patch.\\n\\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1286//console\\n\\nThis message is automatically generated.\\nattaching result of:\\ngit diff --no-prefix fa23683720 57d9df3\\nSince the previous patch (the standard git/GitHub patch [1]) didn't apply correctly, I've attached the git diff result as specified on the Hadoop wiki [2]\\n\\n[1] https://github.com/costin/hadoop-common/commit/57d9df37e600dd588a737d67b271657561ebfea2.patch\\n[2] http://wiki.apache.org/hadoop/GitAndHadoop\\n-1 overall.  Here are the results of testing the latest attachment \\n  http://issues.apache.org/jira/secure/attachment/12540887/HADOOP-8632.patch\\n  against trunk revision .\\n\\n    -1 patch.  The patch command could not apply the patch.\\n\\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1295//console\\n\\nThis message is automatically generated.\\nGuys I'm not sure why the patch doesn't apply - I've followed verbatim the instructions from the wiki. Any ideas on what's missing?\\nWhen I try to apply the patch to trunk I get\\n{noformat}\\n$ patch -p 0 < HADOOP-8632.patch \\npatching file hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java\\nHunk #3 succeeded at 1532 (offset 55 lines).\\npatching file hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java\\nHunk #2 FAILED at 1044.\\n1 out of 2 hunks FAILED -- saving rejects to file hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java.rej\\n{noformat}\\n\\nYou may want to try upmerging the patch to trunk.\\nAttaching the patch against the trunk (the previous patch as mentioned, was against branch-2.1.0-alpha).\\nRan\\ngit diff --no-prefix 7a3427d \\n\",\n          \" | (x) *{color:red}-1 overall{color}* |\\n\\\\\\\\\\n\\\\\\\\\\n|| Vote || Subsystem || Runtime || Comment ||\\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 41s {color} | {color:green} trunk passed {color} |\\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 49s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 37s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |\\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} trunk passed {color} |\\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 50s {color} | {color:green} trunk passed {color} |\\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 53s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 43s {color} | {color:green} the patch passed {color} |\\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 44s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 44s {color} | {color:green} the patch passed {color} |\\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 47s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 47s {color} | {color:green} the patch passed {color} |\\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 14s {color} | {color:red} Patch generated 2 new checkstyle issues in hadoop-common-project/hadoop-common (total was 92, now 94). {color} |\\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 1s {color} | {color:green} the patch passed {color} |\\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |\\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 55s {color} | {color:green} the patch passed {color} |\\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 51s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 6m 44s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_66. {color} |\\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 36s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_91. {color} |\\n| {color:green}+1{color \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hadoop_issues_inspected = pd.read_excel('hadoop_issues_inspected.xlsx')\n",
        "\n",
        "# Assuming 'issue_key' is the common column in both dataframes\n",
        "df_merged = pd.merge(df_hadoop_issues_inspected, df_my_hadoop_selected_issues, on='issue_key', how='left')\n",
        "\n",
        "df_hadoop_issues_merged = df_merged[['issue_key', 'issue_type_x', 'status_x', 'created_date', 'resolved_date', 'time_resolution',\n",
        "                                    'summary_x', 'description',  'architectural_impact','comments']]\n",
        "\n",
        "df_hadoop_issues_merged.rename(columns={'issue_type_x': 'issue_type', 'status_x': 'status', 'summary_x':'summary'}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeFR8kGvzVuJ",
        "outputId": "0479d28a-7d13-479a-9c0e-71979c363326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "<ipython-input-17-4b9de8e17f71>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_hadoop_issues_merged.rename(columns={'issue_type_x': 'issue_type', 'status_x': 'status', 'summary_x':'summary'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hadoop_issues = df_hadoop_issues_merged.copy()\n",
        "df_hadoop_issues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "sdAWTrMQz2Be",
        "outputId": "33e1adca-4c32-4540-91c5-0e3c2fa5dde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        issue_key   issue_type    status created_date resolved_date  \\\n",
              "0     HADOOP-6252  Improvement    Closed   2009-09-10    2009-09-11   \n",
              "1     HADOOP-6184          Bug    Closed   2009-08-10    2009-08-24   \n",
              "2     HADOOP-6165  New Feature    Closed   2009-07-22    2009-09-03   \n",
              "3     HADOOP-6161  Improvement    Closed   2009-07-18    2009-07-20   \n",
              "4     HADOOP-6103          Bug    Closed   2009-06-24    2009-08-21   \n",
              "..            ...          ...       ...          ...           ...   \n",
              "143  HADOOP-18266     Sub-task  Resolved   2022-05-27    2022-06-20   \n",
              "144  HADOOP-18229     Sub-task  Resolved   2022-05-09    2022-05-18   \n",
              "145  HADOOP-18190     Sub-task  Resolved   2022-03-29    2022-07-26   \n",
              "146  HADOOP-18180     Sub-task  Resolved   2022-03-28    2022-04-04   \n",
              "147  HADOOP-18379     Sub-task  Resolved   2022-07-28    2022-08-03   \n",
              "\n",
              "     time_resolution                                            summary  \\\n",
              "0                1.0  Provide method to determine if a deprecated ke...   \n",
              "1               14.0       Provide a configuration dump in json format.   \n",
              "2               43.0                     Add metadata to Serializations   \n",
              "3                2.0                   Add get/setEnum to Configuration   \n",
              "4               58.0  Configuration clone constructor does not clone...   \n",
              "..               ...                                                ...   \n",
              "143             24.0  Replace with HashSet/TreeSet constructor in Ha...   \n",
              "144              9.0                  Fix Hadoop Common Java Doc Errors   \n",
              "145            119.0        Collect IOStatistics during S3A prefetching   \n",
              "146              7.0  Remove use of scala jar twitter util-core with...   \n",
              "147              6.0  rebase feature/HADOOP-18028-s3a-prefetch to trunk   \n",
              "\n",
              "                                           description architectural_impact  \\\n",
              "0     HADOOP-6105 provided a method to deprecate co...                   NO   \n",
              "1                Configuration dump in json format. \\n                  YES   \n",
              "2     The Serialization framework only allows a cla...                  YES   \n",
              "3     It would be useful if Configuration had helpe...                   NO   \n",
              "4     Currently, Configuration(Configuration other)...                   NO   \n",
              "..                                                 ...                  ...   \n",
              "143                                                 \\n                   NO   \n",
              "144   I found that when hadoop-multibranch compiled...                   NO   \n",
              "145   There is a lot more happening in reads, so th...                  YES   \n",
              "146   This jar will cause trouble for scala project...                   NO   \n",
              "147   rebase to trunk, fix conflicts and tests, for...                   NO   \n",
              "\n",
              "                                              comments  \n",
              "0     Patch:\\n   * Implements new method to see if ...  \n",
              "1     In order to generate the  dump in standard fo...  \n",
              "2     Here's a patch with some ideas about how to g...  \n",
              "3     +1 overall.  Here are the results of testing ...  \n",
              "4     defaultResources is a private static list. Th...  \n",
              "..                                                 ...  \n",
              "143   Thanks [~samrat007]  for the patch. Have comm...  \n",
              "144   FIx  <p> not end\\n\\n[ERROR] /home/jenkins/jen...  \n",
              "145   we really do need these to see what is going ...  \n",
              "146   Added https://github.com/apache/hadoop/pull/4...  \n",
              "147                                                 \\n  \n",
              "\n",
              "[148 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4c76012-89de-4e0b-acc4-83759fddf60d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_key</th>\n",
              "      <th>issue_type</th>\n",
              "      <th>status</th>\n",
              "      <th>created_date</th>\n",
              "      <th>resolved_date</th>\n",
              "      <th>time_resolution</th>\n",
              "      <th>summary</th>\n",
              "      <th>description</th>\n",
              "      <th>architectural_impact</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HADOOP-6252</td>\n",
              "      <td>Improvement</td>\n",
              "      <td>Closed</td>\n",
              "      <td>2009-09-10</td>\n",
              "      <td>2009-09-11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Provide method to determine if a deprecated ke...</td>\n",
              "      <td>HADOOP-6105 provided a method to deprecate co...</td>\n",
              "      <td>NO</td>\n",
              "      <td>Patch:\\n   * Implements new method to see if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HADOOP-6184</td>\n",
              "      <td>Bug</td>\n",
              "      <td>Closed</td>\n",
              "      <td>2009-08-10</td>\n",
              "      <td>2009-08-24</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Provide a configuration dump in json format.</td>\n",
              "      <td>Configuration dump in json format. \\n</td>\n",
              "      <td>YES</td>\n",
              "      <td>In order to generate the  dump in standard fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HADOOP-6165</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>Closed</td>\n",
              "      <td>2009-07-22</td>\n",
              "      <td>2009-09-03</td>\n",
              "      <td>43.0</td>\n",
              "      <td>Add metadata to Serializations</td>\n",
              "      <td>The Serialization framework only allows a cla...</td>\n",
              "      <td>YES</td>\n",
              "      <td>Here's a patch with some ideas about how to g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HADOOP-6161</td>\n",
              "      <td>Improvement</td>\n",
              "      <td>Closed</td>\n",
              "      <td>2009-07-18</td>\n",
              "      <td>2009-07-20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Add get/setEnum to Configuration</td>\n",
              "      <td>It would be useful if Configuration had helpe...</td>\n",
              "      <td>NO</td>\n",
              "      <td>+1 overall.  Here are the results of testing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HADOOP-6103</td>\n",
              "      <td>Bug</td>\n",
              "      <td>Closed</td>\n",
              "      <td>2009-06-24</td>\n",
              "      <td>2009-08-21</td>\n",
              "      <td>58.0</td>\n",
              "      <td>Configuration clone constructor does not clone...</td>\n",
              "      <td>Currently, Configuration(Configuration other)...</td>\n",
              "      <td>NO</td>\n",
              "      <td>defaultResources is a private static list. Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>HADOOP-18266</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>2022-06-20</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Replace with HashSet/TreeSet constructor in Ha...</td>\n",
              "      <td>\\n</td>\n",
              "      <td>NO</td>\n",
              "      <td>Thanks [~samrat007]  for the patch. Have comm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>HADOOP-18229</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>2022-05-09</td>\n",
              "      <td>2022-05-18</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Fix Hadoop Common Java Doc Errors</td>\n",
              "      <td>I found that when hadoop-multibranch compiled...</td>\n",
              "      <td>NO</td>\n",
              "      <td>FIx  &lt;p&gt; not end\\n\\n[ERROR] /home/jenkins/jen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>HADOOP-18190</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>2022-03-29</td>\n",
              "      <td>2022-07-26</td>\n",
              "      <td>119.0</td>\n",
              "      <td>Collect IOStatistics during S3A prefetching</td>\n",
              "      <td>There is a lot more happening in reads, so th...</td>\n",
              "      <td>YES</td>\n",
              "      <td>we really do need these to see what is going ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>HADOOP-18180</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>2022-03-28</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Remove use of scala jar twitter util-core with...</td>\n",
              "      <td>This jar will cause trouble for scala project...</td>\n",
              "      <td>NO</td>\n",
              "      <td>Added https://github.com/apache/hadoop/pull/4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>HADOOP-18379</td>\n",
              "      <td>Sub-task</td>\n",
              "      <td>Resolved</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-03</td>\n",
              "      <td>6.0</td>\n",
              "      <td>rebase feature/HADOOP-18028-s3a-prefetch to trunk</td>\n",
              "      <td>rebase to trunk, fix conflicts and tests, for...</td>\n",
              "      <td>NO</td>\n",
              "      <td>\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4c76012-89de-4e0b-acc4-83759fddf60d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4c76012-89de-4e0b-acc4-83759fddf60d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4c76012-89de-4e0b-acc4-83759fddf60d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ed8abe8-9d21-4ec1-ba81-1a04ebf3307e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ed8abe8-9d21-4ec1-ba81-1a04ebf3307e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ed8abe8-9d21-4ec1-ba81-1a04ebf3307e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_19db65d2-dd16-43da-8229-8a7a6a67614a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_hadoop_issues')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_19db65d2-dd16-43da-8229-8a7a6a67614a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_hadoop_issues');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_hadoop_issues",
              "summary": "{\n  \"name\": \"df_hadoop_issues\",\n  \"rows\": 148,\n  \"fields\": [\n    {\n      \"column\": \"issue_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"HADOOP-16654\",\n          \"HADOOP-8525\",\n          \"HADOOP-17957\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Improvement\",\n          \"Bug\",\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Closed\",\n          \"Resolved\",\n          \"Open\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \"2019-01-29\",\n          \"2010-01-22\",\n          \"2014-11-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resolved_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 139,\n        \"samples\": [\n          \"2022-05-18\",\n          \"2013-06-18\",\n          \"2011-07-07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_resolution\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 301.6019701035379,\n        \"min\": 0.0,\n        \"max\": 1949.0,\n        \"num_unique_values\": 74,\n        \"samples\": [\n          58.0,\n          57.0,\n          85.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"Delete hadoop-ozone and hadoop-hdds subprojects from apache trunk\",\n          \"Provide Improved Traceability for Configuration\",\n          \"Replace Guava VisibleForTesting by Hadoop's own annotation in hadoop-hdfs-project modules\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 141,\n        \"samples\": [\n          \" The following Javadoc of FSDataOutputStream is wrong.\\n{quote}\\n  buffers output through a \\\\{@link BufferedOutputStream\\\\} and creates a checksum file.\\n{quote}\\nFSDataOutputStream has nothing to do with a BufferedOutputStream. Neither it create a checksum file.\\n \\n\",\n          \" Rename properties with prefix dfs.adls. to fs.adl.\\nRename adl.dfs.enable.client.latency.tracker to adl.enable.client.latency.tracker \\n\",\n          \" Fix incomplete merge from yahoo-merge branch to trunk: \\n-r 1079167: Generalize StringUtils::join (Chris Douglas) \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"architectural_impact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"YES\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \" Attached patch refactors out the config-parsing code to a new inner class with a bunch of smaller functions which are easier to compile. I also took the opportunity to make a few micro-optimizations like avoiding construction of the confSources array in the common case that the config file uses no \\\"<source>\\\" tags.\\n\\nI tested the improvement by running:\\n\\n{code}\\nfor x in $(seq 1 60); do\\n  java -XX:+CITime -cp hadoop-common-project/hadoop-common/target/hadoop-common-3.2.0-SNAPSHOT.jar:$CP \\\\\\n         org.apache.hadoop.examples.ExampleDriver pi 1 1 2>&1  \\\\\\n       | grep 'Total comp'\\ndone | tee /tmp/patch.txt\\n{code}\\n\\nto measure the total compilation time in a simple LocalJobRunner MR job. I grepped out the times and ran a t-test using R:\\n\\n{code}\\ndata:  d.orig and d.patched\\nt = 36.511, df = 110.1, p-value < 2.2e-16\\nalternative hypothesis: true difference in means is not equal to 0\\n95 percent confidence interval:\\n 0.7329980 0.8171354\\nsample estimates:\\nmean of x mean of y\\n 3.508300  2.733233\\n{code}\\n\\nSo this saves about 730-810ms of CPU time spent by the JIT.\\n\\nTo test throughput, I used the ConfTest.java program from HADOOP-14216.\\n\\n{code}\\norig:\\n\\nduration: 20745 count: 3561000\\n\\nreal    0m21.104s\\nuser    0m29.296s\\nsys     0m1.903s\\n\\npatch:\\n\\nduration: 21810 count: 3561000\\n\\nreal    0m22.304s\\nuser    0m27.013s\\nsys     0m2.547s\\n{code}\\n\\nSo it seems around the same - a bit less user time, a bit longer real time. Close enough to call \\\"not a regression\\\".\\n\\nI also tried 'fs -ls hdfs://nn/' under 'perf stat -r10':\\n\\n{code}\\norig:\\n\\n\\n       5295.930635      task-clock (msec)         #    3.454 CPUs utilized            ( +-  3.56% )\\n            10,977      context-switches          #    0.002 M/sec                    ( +-  0.37% )\\n               613      cpu-migrations            #    0.116 K/sec                    ( +-  2.28% )\\n            86,804      page-faults               #    0.016 M/sec                    ( +-  0.12% )\\n    14,823,251,627      cycles                    #    2.799 GHz                      ( +-  3.61% )\\n    11,367,265,626      instructions              #    0.77  insn per cycle           ( +-  1.81% )\\n     2,503,093,507      branches                  #  472.645 M/sec                    ( +-  3.26% )\\n        67,066,880      branch-misses             #    2.68% of all branches          ( +-  0.23% )\\n\\n       1.533354188 seconds time elapsed                                          ( +-  0.54% )\\n\\npatch:\\n\\n       5173.366209      task-clock (msec)         #    3.384 CPUs utilized            ( +-  3.60% )\\n            11,160      context-switches          #    0.002 M/sec                    ( +-  1.32% )\\n               630      cpu-migrations            #    0.122 K/sec                    ( +-  2.82% )\\n            87,732      page-faults               #    0.017 M/sec                    ( +-  0.18% )\\n    14,495,009,185      cycles                    #    2.802 GHz                      ( +-  3.55% )\\n    11,485,553,655      instructions              #    0.79  insn per cycle           ( +-  1.80% )\\n     2,487,385,519      branches                  #  480.806 M/sec                    ( +-  3.34% )\\n        68,583,976      branch-misses             #    2.76% of all branches          ( +-  0.25% )\\n\\n       1.528788291 seconds time elapsed                                          ( +-  0.62% )\\n{code}\\n\\n and 'yarn application -list' on an RM running no applications:\\n\\n{code}\\norig:\\n       2150.752819      task-clock (msec)         #    2.101 CPUs utilized            ( +-  0.89% )\\n             9,179      context-switches          #    0.004 M/sec                    ( +-  0.66% )\\n               476      cpu-migrations            #    0.221 K/sec                    ( +-  3.20% )\\n            46,036      page-faults               #    0.021 M/sec                    ( +-  0.13% )\\n     5,928,445,661      cycles                    #    2.756 GHz                      ( +-  0. \\n\",\n          \" We can do something like:\\n{code}\\n+    if (conf.getBoolean(\\\"mapred.jobconf.notpresent\\\", false)) {\\n+      return;//classpath check already done and jobconf is not in classpath.\\n+    }\\n     try {\\n       Class<?> jobConfClass = \\n         conf.getClassByName(\\\"org.apache.hadoop.mapred.JobConf\\\");\\n@@ -86,9 +89,11 @@ public class ReflectionUtils {\\n         Method configureMethod = \\n           jobConfigurableClass.getMethod(\\\"configure\\\", jobConfClass);\\n         configureMethod.invoke(theObject, conf);\\n+        \\n       }\\n     } catch (ClassNotFoundException e) {\\n       //JobConf/JobConfigurable not in classpath. no need to configure\\n+      conf.setBoolean(\\\"mapred.jobconf.notpresent\\\", true);\\n     }\\n{code}\\nI think the performance issue only comes if jobconf is not in classpath resulting in ClassNotFoundException on each check. Hairong, can you please verify if the above fix helps ?\\n\\nIs  this dangerous? Will we ever have a case where the JobConf isn't in the classpath once, and then later shows up because the classloader changed?\\nI don't think it's appropriate to cache JVM state in the configuration.\\n\\nI think we can better fix this by changing Configuration#getClassByName() to cache failures as well as successes.\\n\\n> Will we ever have a case where the JobConf isn't in the classpath once, and then later shows up because the classloader changed?\\n\\nThe cache in Configuration is per-classloader.  So as long as we go through that we should be safe.\\n\\n_DistributedFileSystem#listStatus requires checking the JobConf class._\\n\\nThe above statement sounds totally wrong to me.  If mapreduce needs a special ReflectionUtils, why don't we add one in mapreduce?\\nNicholas: the problem is that ReflectionUtils.getInstance gets called by common code in Configuration. MapReduce wouldn't just need its own ReflectionUtils, it would also need its own Configuration, no?\\nSince JobConf extends Configuration, could JobConf override the common codes ?\\nActually, after thinking some more, even that wouldn't work. There's lots of Common code that uses ReflectionUtils.newInstance, for example the serialziation stuff which instantiates writables. A user is free to make their writables JobConfigurable, etc. I don't think there's a particularly simple solution here.\\n\\nbq. The cache in Configuration is per-classloader. So as long as we go through that we should be safe.\\n\\nIf we make the assumption that classloaders never pick up new classes, that's true. But I don't think the JVM has a negative class cache, does it? That is, if you try to load a class when it doesn't exist, then move the class into the classpath and try to load again, it might pick it up.\\n> If we make the assumption that classloaders never pick up new classes, that's true.\\n\\nI am happy to make that assumption.  I don't think dynamically adding classes to a class path as an application runs is a pattern we need to support.  Consider the case where you place a different definition earlier in the classpath.  No cache would pick that up.  Caching negatives seems like a very small step beyond that.\\nbq.  I don't think dynamically adding classes to a class path as an application runs is a pattern we need to support.\\n\\nI tend to agree. Steve Loughran - you out there? I think you probably are the one doing the wackiest stuff with classloaders and Hadoop :)\\n_Disclaimer_ I have long advocated having a ASF exam in classloaders; nobody who hasn't passed the exam would be allowed to mess with classloaders in any apache project. As there is no such exam, there is no proof that I can be considered competent enough to do this, and you should treat everything I say with caution. Test my statements, preferably in JUnit methods.\\n\\n1.  Adding new classes is generally rare unless you are running something that is generating java classes on the fly; JSP compilers do this. Even then, they try not to mess around with things higher up the hierarchy (exception, JBoss default classloader, the one that's broken that everyone hates).\\n\\n2. Modern, OSGi \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqK2rHwSz5t2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}